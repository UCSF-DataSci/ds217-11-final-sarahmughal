{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "170920c8",
   "metadata": {},
   "source": [
    "# Q6: Modeling Preparation\n",
    "\n",
    "**Phase 7:** Modeling Preparation  \n",
    "**Points: 3 points**\n",
    "\n",
    "**Focus:** Perform temporal train/test split, select features, handle categorical variables.\n",
    "\n",
    "**Lecture Reference:** Lecture 11, Notebook 3 ([`11/demo/03_pattern_analysis_modeling_prep.ipynb`](https://github.com/christopherseaman/datasci_217/blob/main/11/demo/03_pattern_analysis_modeling_prep.ipynb)), Phase 7. This notebook demonstrates temporal train/test splitting (see \"Your Approach\" section below for the key code pattern).\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3645955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 196,279 records with features\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load feature-engineered data from Q4\n",
    "df = pd.read_csv(\n",
    "    \"output/q4_features.csv\",\n",
    "    parse_dates=[\"Measurement Timestamp\"],\n",
    "    index_col=\"Measurement Timestamp\",\n",
    ")\n",
    "# Or if you saved without index:\n",
    "# df = pd.read_csv('output/q4_features.csv')\n",
    "# df['Measurement Timestamp'] = pd.to_datetime(df['Measurement Timestamp'])\n",
    "# df = df.set_index('Measurement Timestamp')\n",
    "print(f\"Loaded {len(df):,} records with features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dc8e59",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Prepare data for modeling by performing temporal train/test split, selecting features, and handling categorical variables.\n",
    "\n",
    "**CRITICAL - Temporal Split:** For time series data, you **MUST** use temporal splitting (earlier data for training, later data for testing). **DO NOT** use random split. Why? Time series data has temporal dependencies - using future data to predict the past would be data leakage.\n",
    "\n",
    "---\n",
    "\n",
    "## Required Artifacts\n",
    "\n",
    "You must create exactly these 5 files in the `output/` directory:\n",
    "\n",
    "### 1. `output/q6_X_train.csv`\n",
    "**Format:** CSV file\n",
    "**Content:** Training features (X)\n",
    "**Requirements:**\n",
    "- All feature columns (no target variable)\n",
    "- Only training data (earlier time periods)\n",
    "- **No index column** (save with `index=False`)\n",
    "- **No datetime column** (unless it's a feature, not the index)\n",
    "\n",
    "### 2. `output/q6_X_test.csv`\n",
    "**Format:** CSV file\n",
    "**Content:** Test features (X)\n",
    "**Requirements:**\n",
    "- All feature columns (same as X_train)\n",
    "- Only test data (later time periods)\n",
    "- **No index column** (save with `index=False`)\n",
    "- **No datetime column** (unless it's a feature, not the index)\n",
    "\n",
    "### 3. `output/q6_y_train.csv`\n",
    "**Format:** CSV file\n",
    "**Content:** Training target variable (y)\n",
    "**Requirements:**\n",
    "- Single column with target variable name as header\n",
    "- Only training data (corresponding to X_train)\n",
    "- **No index column** (save with `index=False`)\n",
    "\n",
    "**Example:**\n",
    "```csv\n",
    "Water Temperature\n",
    "15.2\n",
    "15.3\n",
    "15.1\n",
    "...\n",
    "```\n",
    "\n",
    "### 4. `output/q6_y_test.csv`\n",
    "**Format:** CSV file\n",
    "**Content:** Test target variable (y)\n",
    "**Requirements:**\n",
    "- Single column with target variable name as header\n",
    "- Only test data (corresponding to X_test)\n",
    "- **No index column** (save with `index=False`)\n",
    "\n",
    "### 5. `output/q6_train_test_info.txt`\n",
    "**Format:** Plain text file\n",
    "**Content:** Train/test split information\n",
    "**Required information:**\n",
    "- Split method: Temporal (80/20 or similar)\n",
    "- Training set size: [number] samples\n",
    "- Test set size: [number] samples\n",
    "- Training date range: [start] to [end]\n",
    "- Test date range: [start] to [end]\n",
    "- Number of features: [number]\n",
    "- Target variable: [name]\n",
    "\n",
    "**Example format:**\n",
    "```\n",
    "TRAIN/TEST SPLIT INFORMATION\n",
    "==========================\n",
    "\n",
    "Split Method: Temporal (80/20 split by time)\n",
    "\n",
    "Training Set Size: 40000 samples\n",
    "Test Set Size: 10000 samples\n",
    "\n",
    "Training Date Range: 2022-01-01 00:00:00 to 2026-09-15 07:00:00\n",
    "Test Date Range: 2026-09-15 08:00:00 to 2027-09-15 07:00:00\n",
    "\n",
    "Number of Features: 22\n",
    "Target Variable: Water Temperature\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements Checklist\n",
    "\n",
    "- [ ] Target variable selected\n",
    "- [ ] Temporal train/test split performed (train on earlier data, test on later data - **NOT random split**)\n",
    "- [ ] Features selected and prepared\n",
    "- [ ] Categorical variables handled (encoding if needed)\n",
    "- [ ] No data leakage (future data not in training set)\n",
    "- [ ] All 5 required artifacts saved with exact filenames\n",
    "\n",
    "---\n",
    "\n",
    "## Your Approach\n",
    "\n",
    "1. **Select target variable** - Choose a meaningful numeric variable to predict\n",
    "2. **Select features** - Exclude target, non-numeric columns, and any features derived from the target (to avoid data leakage)\n",
    "3. **Handle categorical variables** - One-hot encode if needed\n",
    "4. **Perform temporal train/test split** - Sort by datetime, then split by index position (earlier data for training, later for testing)\n",
    "5. **Save artifacts** - Save X_train, X_test, y_train, y_test as separate CSVs\n",
    "6. **Document split** - Record split sizes, date ranges, and feature count\n",
    "\n",
    "---\n",
    "\n",
    "## Feature Selection Guidelines\n",
    "\n",
    "When selecting features for modeling, think critically about each feature:\n",
    "\n",
    "**Red Flags to Watch For:**\n",
    "- **Circular logic**: Does this feature use the target variable to predict the target?\n",
    "  - Example: Rolling mean of target, lag of target (if not handled carefully)\n",
    "  - Example: If predicting `Air Temperature`, using `air_temp_rolling_7h` is circular - you're predicting temperature from smoothed temperature\n",
    "- **Data leakage**: Does this feature contain information that wouldn't be available at prediction time?\n",
    "  - Example: Future values, aggregated statistics that include the current value\n",
    "- **Near-duplicates**: Is this feature nearly identical to the target?\n",
    "  - Check correlations - if correlation > 0.95, investigate whether it's legitimate\n",
    "  - Example: A feature with 99%+ correlation with the target is likely problematic\n",
    "\n",
    "**Good Practices:**\n",
    "- Use external predictors (other weather variables, temporal features)\n",
    "- Create rolling windows of **predictors**, not the target\n",
    "  - Good: `wind_speed_rolling_7h`, `humidity_rolling_24h`\n",
    "  - Bad: `air_temp_rolling_7h` when predicting Air Temperature\n",
    "- Use derived features that combine multiple predictors\n",
    "- Think: \"Would I have this information when making a real prediction?\"\n",
    "\n",
    "**Remember:** The goal is to predict the target from **other** information, not from the target itself.\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Points\n",
    "\n",
    "- **Target variable:** What do you want to predict? Temperature? Water conditions? Choose something meaningful and measurable.\n",
    "- **Temporal split:** **CRITICAL** - Use temporal split (earlier data for training, later data for testing), NOT random split. Why? Time series data has temporal dependencies. Typical split: 80/20 or 70/30.\n",
    "- **Feature selection:** Which features are most relevant? Consider correlations, domain knowledge, and feature importance from previous analysis.\n",
    "- **Categorical encoding:** If you have categorical variables, encode them (one-hot encoding, label encoding, etc.) before modeling.\n",
    "\n",
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "After Q6, you should have:\n",
    "- [ ] Temporal train/test split completed (earlier → train, later → test)\n",
    "- [ ] Features prepared (no target, no datetime index)\n",
    "- [ ] Categorical variables encoded\n",
    "- [ ] No data leakage verified\n",
    "- [ ] All 5 artifacts saved: `q6_X_train.csv`, `q6_X_test.csv`, `q6_y_train.csv`, `q6_y_test.csv`, `q6_train_test_info.txt`\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Continue to `q7_modeling.md` for Modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a991cb",
   "metadata": {},
   "source": [
    "## Generate Artifacts 1-4 (X Train & Test, y Train & Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8df1472d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved X_train ((157023, 16)), X_test ((39256, 16)), y_train ((157023,)), y_test ((39256,))\n"
     ]
    }
   ],
   "source": [
    "target_col = \"Air Temperature\"\n",
    "\n",
    "# Columns that would cause leakage (derived from target) or are IDs/labels\n",
    "leak_or_id_cols = [\n",
    "    \"Air Temperature (F)\",\n",
    "    \"Comfort Index\",\n",
    "    \"Temp Ratio\",\n",
    "    \"Temperature Difference\",\n",
    "    \"Air Temperature Categories\",\n",
    "    \"Measurement ID\",\n",
    "    \"Measurement Timestamp Label\",\n",
    "]\n",
    "\n",
    "# Categorical columns to one-hot encode\n",
    "cat_cols = [\n",
    "    \"Station Name\",\n",
    "    \"Precipitation Type\",\n",
    "    \"Air Temperature Categories\",\n",
    "    \"Wind Speed Categories\",\n",
    "]\n",
    "\n",
    "# y: target\n",
    "y = df[target_col].copy()\n",
    "\n",
    "# X: drop target + leakage/ID cols\n",
    "X = df.drop(columns=[c for c in [target_col] + leak_or_id_cols if c in df.columns])\n",
    "\n",
    "# One-hot encode categoricals\n",
    "X = pd.get_dummies(X, columns=[c for c in cat_cols if c in X.columns], drop_first=True)\n",
    "\n",
    "# Temporal 80/20 train/test split\n",
    "n = len(X)\n",
    "split_idx = int(n * 0.8)\n",
    "\n",
    "X_train = X.iloc[:split_idx].reset_index(drop=True)\n",
    "X_test = X.iloc[split_idx:].reset_index(drop=True)\n",
    "y_train = y.iloc[:split_idx].reset_index(drop=True)\n",
    "y_test = y.iloc[split_idx:].reset_index(drop=True)\n",
    "\n",
    "# Save artifacts 1–4\n",
    "X_train.to_csv(\"output/q6_X_train.csv\", index=False)\n",
    "X_test.to_csv(\"output/q6_X_test.csv\", index=False)\n",
    "y_train.to_csv(\"output/q6_y_train.csv\", index=False, header=[target_col])\n",
    "y_test.to_csv(\"output/q6_y_test.csv\", index=False, header=[target_col])\n",
    "\n",
    "print(\n",
    "    f\"Saved X_train ({X_train.shape}), X_test ({X_test.shape}), y_train ({y_train.shape}), y_test ({y_test.shape})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb75b85",
   "metadata": {},
   "source": [
    "## Generate Artifact 5 (q6_train_test_info.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154865a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved q6_train_test_info.txt\n"
     ]
    }
   ],
   "source": [
    "train_dates = df.index[:split_idx]\n",
    "test_dates = df.index[split_idx:]\n",
    "\n",
    "info_lines = []\n",
    "info_lines.append(\"TRAIN/TEST SPLIT INFORMATION\")\n",
    "info_lines.append(\"==========================\")\n",
    "info_lines.append(\"\")\n",
    "info_lines.append(\"Split Method: Temporal (80/20 split by time)\")\n",
    "info_lines.append(\"\")\n",
    "info_lines.append(f\"Training Set Size: {len(X_train)} samples\")\n",
    "info_lines.append(f\"Test Set Size: {len(X_test)} samples\")\n",
    "info_lines.append(\"\")\n",
    "info_lines.append(f\"Training Date Range: {train_dates.min()} to {train_dates.max()}\")\n",
    "info_lines.append(f\"Test Date Range: {test_dates.min()} to {test_dates.max()}\")\n",
    "info_lines.append(\"\")\n",
    "info_lines.append(f\"Number of Features: {X.shape[1]}\")\n",
    "info_lines.append(f\"Target Variable: {target_col}\")\n",
    "\n",
    "with open(\"output/q6_train_test_info.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(info_lines))\n",
    "\n",
    "print(\"Saved q6_train_test_info.txt\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
