{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9331d092",
   "metadata": {},
   "source": [
    "# Q3: Data Wrangling\n",
    "\n",
    "**Phase 4:** Data Wrangling & Transformation  \n",
    "**Points: 9 points**\n",
    "\n",
    "**Focus:** Parse datetime columns, set datetime index, extract time-based features.\n",
    "\n",
    "**Lecture Reference:** Lecture 11, Notebook 2 ([`11/demo/02_wrangling_feature_engineering.ipynb`](https://github.com/christopherseaman/datasci_217/blob/main/11/demo/02_wrangling_feature_engineering.ipynb)), Phase 4. Also see Lecture 09 (time series).\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d790dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 196,279 cleaned records\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load cleaned data from Q2\n",
    "df = pd.read_csv(\"output/q2_cleaned_data.csv\")\n",
    "print(f\"Loaded {len(df):,} cleaned records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71d8451",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Parse datetime columns, set datetime index, and extract temporal features for time series analysis.\n",
    "\n",
    "**Time Series Note:** This dataset is time-series data (sensor readings over time), unlike the lecture's event-based taxi data. You'll work with a datetime index and extract temporal features (hour, day_of_week, month) that are essential for time series analysis. See **Lecture 09** for time series operations. Use pandas datetime index properties (`.hour`, `.dayofweek`, `.month`, etc.) to extract temporal features from your datetime index.\n",
    "\n",
    "---\n",
    "\n",
    "## Required Artifacts\n",
    "\n",
    "You must create exactly these 3 files in the `output/` directory:\n",
    "\n",
    "### 1. `output/q3_wrangled_data.csv`\n",
    "**Format:** CSV file\n",
    "**Content:** Dataset with datetime index set\n",
    "**Requirements:**\n",
    "- Datetime column parsed using `pd.to_datetime()`\n",
    "- Datetime column set as index using `df.set_index()`\n",
    "- Index sorted chronologically using `df.sort_index()`\n",
    "- **When saving:** Reset index to save datetime as column: `df.reset_index().to_csv(..., index=False)`\n",
    "- All original columns preserved\n",
    "- **No extra index column** (save with `index=False`)\n",
    "\n",
    "### 2. `output/q3_temporal_features.csv`\n",
    "**Format:** CSV file\n",
    "**Required Columns (exact names):** Must include at minimum:\n",
    "- Original datetime column (e.g., `Measurement Timestamp` or `datetime`)\n",
    "- `hour` (integer, 0-23)\n",
    "- `day_of_week` (integer, 0=Monday, 6=Sunday)\n",
    "- `month` (integer, 1-12)\n",
    "\n",
    "**Optional but recommended:**\n",
    "- `year` (integer)\n",
    "- `day_name` (string, e.g., \"Monday\")\n",
    "- `is_weekend` (integer, 0 or 1)\n",
    "\n",
    "**Content:** DataFrame with datetime column and extracted temporal features\n",
    "**Requirements:**\n",
    "- At minimum: datetime column, `hour`, `day_of_week`, `month`\n",
    "- All values must be valid (no NaN in required columns)\n",
    "- **No index column** (save with `index=False`)\n",
    "\n",
    "**Example columns:**\n",
    "```csv\n",
    "Measurement Timestamp,hour,day_of_week,month,year,day_name,is_weekend\n",
    "2022-01-01 00:00:00,0,5,1,2022,Saturday,1\n",
    "2022-01-01 01:00:00,1,5,1,2022,Saturday,1\n",
    "...\n",
    "```\n",
    "\n",
    "### 3. `output/q3_datetime_info.txt`\n",
    "**Format:** Plain text file\n",
    "**Content:** Date range information after datetime parsing\n",
    "**Required information:**\n",
    "- Start date (earliest datetime)\n",
    "- End date (latest datetime)\n",
    "- Total duration (optional but recommended)\n",
    "\n",
    "**Example format:**\n",
    "```\n",
    "Date Range After Datetime Parsing:\n",
    "Start: 2022-01-01 00:00:00\n",
    "End: 2027-09-15 07:00:00\n",
    "Total Duration: 5 years, 8 months, 14 days, 7 hours\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements Checklist\n",
    "\n",
    "- [ ] Datetime columns parsed correctly using `pd.to_datetime()`\n",
    "- [ ] Datetime index set using `df.set_index()`\n",
    "- [ ] Index sorted chronologically using `df.sort_index()`\n",
    "- [ ] Temporal features extracted: `hour`, `day_of_week`, `month` (minimum)\n",
    "- [ ] All 3 required artifacts saved with exact filenames\n",
    "\n",
    "---\n",
    "\n",
    "## Your Approach\n",
    "\n",
    "1. **Parse datetime** - Convert datetime column using `pd.to_datetime()`\n",
    "2. **Set datetime index** - Set as index and sort chronologically\n",
    "3. **Extract temporal features** - Use datetime index properties (`.hour`, `.dayofweek`, `.month`, etc.)\n",
    "4. **Save artifacts** - Remember to `reset_index()` before saving CSVs so the datetime becomes a column\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Points\n",
    "\n",
    "- **Datetime parsing:** What format is your datetime column? Use `pd.to_datetime()` with appropriate format string if needed: `pd.to_datetime(df[col], format='%Y-%m-%d %H:%M:%S')`\n",
    "- **Temporal features:** Extract at minimum: hour, day_of_week, month. Consider also: year, day_name, is_weekend, time_of_day categories. What makes sense for your analysis?\n",
    "\n",
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "After Q3, you should have:\n",
    "- [ ] Datetime columns parsed\n",
    "- [ ] Datetime index set and sorted\n",
    "- [ ] Temporal features extracted (at minimum: hour, day_of_week, month)\n",
    "- [ ] All 3 artifacts saved: `q3_wrangled_data.csv`, `q3_temporal_features.csv`, `q3_datetime_info.txt`\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Continue to `q4_feature_engineering.md` for Feature Engineering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51588e57",
   "metadata": {},
   "source": [
    "## Generate Artifact 1 (q3_wrangled_data.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e9a278d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 196,279 cleaned records\n",
      "Dropped 0 rows with invalid datetimes\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned data from Q2\n",
    "df = pd.read_csv(\"output/q2_cleaned_data.csv\")\n",
    "print(f\"Loaded {len(df):,} cleaned records\")\n",
    "\n",
    "# Convert Measurement Timestamp into datetime object\n",
    "datetime_col = \"Measurement Timestamp\"\n",
    "df[datetime_col] = pd.to_datetime(df[datetime_col], errors=\"coerce\")\n",
    "\n",
    "# Drop rows where datetime is missing (failed parsing)\n",
    "before = len(df)\n",
    "df = df.dropna(subset=[datetime_col])\n",
    "after = len(df)\n",
    "print(f\"Dropped {before - after} rows with invalid datetimes\")\n",
    "\n",
    "# Set datetime index and sort\n",
    "df = df.set_index(datetime_col)\n",
    "df = df.sort_index()\n",
    "\n",
    "# Save wrangled data: reset index so datetime becomes a column again\n",
    "df.reset_index().to_csv(\"output/q3_wrangled_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a997bf07",
   "metadata": {},
   "source": [
    "## Generate Artifact 2 (q3_temporal_features.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18efdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the current df with datetime index\n",
    "temporal_df = pd.DataFrame()\n",
    "temporal_df[datetime_col] = df.index\n",
    "\n",
    "temporal_df[\"hour\"] = df.index.hour\n",
    "temporal_df[\"day_name\"] = df.index.day_name()\n",
    "temporal_df[\"day_of_week\"] = df.index.dayofweek\n",
    "temporal_df[\"month\"] = df.index.month\n",
    "temporal_df[\"year\"] = df.index.year\n",
    "temporal_df[\"is_weekend\"] = (df.index.dayofweek >= 5).astype(int)\n",
    "\n",
    "temporal_df.to_csv(\"output/q3_temporal_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a8cfe1",
   "metadata": {},
   "source": [
    "## Generate Artifact 3 (q3_datetime_info.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fce7145",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = df.index.min()\n",
    "end = df.index.max()\n",
    "duration = end - start\n",
    "total_records = len(df)\n",
    "\n",
    "with open(\"output/q3_datetime_info.txt\", \"w\") as f:\n",
    "    f.write(\"Date Range After Datetime Parsing:\\n\")\n",
    "    f.write(f\"  Start: {start}\\n\")\n",
    "    f.write(f\"  End: {end}\\n\")\n",
    "    f.write(f\"  Total Duration: {duration}\\n\")\n",
    "    f.write(f\"  Total Records: {total_records}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "ds217-11-final-sarahmughal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
