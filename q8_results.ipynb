{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64cac424",
   "metadata": {},
   "source": [
    "# Q8: Results\n",
    "\n",
    "**Phase 9:** Results & Insights  \n",
    "**Points: 3 points**\n",
    "\n",
    "**Focus:** Generate final visualizations, create summary tables, document key findings.\n",
    "\n",
    "**Lecture Reference:** Lecture 11, Notebook 4 ([`11/demo/04_modeling_results.ipynb`](https://github.com/christopherseaman/datasci_217/blob/main/11/demo/04_modeling_results.ipynb)), Phase 9. Also see Lecture 07 (visualization).\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0537730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load model results from Q7\n",
    "predictions = pd.read_csv(\"output/q7_predictions.csv\")\n",
    "metrics = open(\"output/q7_model_metrics.txt\").read()\n",
    "feature_importance = pd.read_csv(\"output/q7_feature_importance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c7560",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Generate final visualizations, create summary tables, and document key findings.\n",
    "\n",
    "---\n",
    "\n",
    "## Required Artifacts\n",
    "\n",
    "You must create exactly these 3 files in the `output/` directory:\n",
    "\n",
    "### 1. `output/q8_final_visualizations.png`\n",
    "**Format:** PNG image file\n",
    "**Content:** Final summary visualizations\n",
    "**Required visualizations (at least 2 of these):**\n",
    "1. **Model performance comparison:** Bar plot or line plot comparing R², RMSE, or MAE across models\n",
    "2. **Predictions vs Actual:** Scatter plot showing predicted vs actual values (with perfect prediction line)\n",
    "3. **Feature importance:** Bar plot showing top N features by importance\n",
    "4. **Residuals plot:** Scatter plot of residuals (actual - predicted) vs predicted\n",
    "\n",
    "**Requirements:**\n",
    "- Clear axis labels (xlabel, ylabel)\n",
    "- Title for each subplot\n",
    "- Overall figure title (optional but recommended)\n",
    "- Legend if multiple series shown\n",
    "- Saved as PNG with sufficient resolution (dpi=150 or higher)\n",
    "\n",
    "### 2. `output/q8_summary.csv`\n",
    "**Format:** CSV file\n",
    "**Content:** Key findings summary table\n",
    "**Required columns:**\n",
    "- `Metric` - Metric name (e.g., \"R² Score\", \"RMSE\", \"MAE\")\n",
    "- One column per model (e.g., `Linear Regression`, `Random Forest`, `XGBoost`)\n",
    "\n",
    "**Requirements:**\n",
    "- Must include at least R², RMSE, MAE metrics\n",
    "- One row per metric\n",
    "- **No index column** (save with `index=False`)\n",
    "\n",
    "**Example:**\n",
    "```csv\n",
    "Metric,Linear Regression,Random Forest,XGBoost\n",
    "R² Score,-0.0201,0.9705,0.9967\n",
    "RMSE,12.7154,2.1634,0.7276\n",
    "MAE,9.8468,1.3545,0.4480\n",
    "```\n",
    "\n",
    "### 3. `output/q8_key_findings.txt`\n",
    "**Format:** Plain text file\n",
    "**Content:** Text summary of main insights\n",
    "**Required information:**\n",
    "- Best performing model and why\n",
    "- Key findings from feature importance\n",
    "- Temporal patterns identified\n",
    "- Data quality summary\n",
    "\n",
    "**Example format:**\n",
    "```\n",
    "KEY FINDINGS SUMMARY\n",
    "===================\n",
    "\n",
    "MODEL PERFORMANCE:\n",
    "- Best performing model: XGBoost (R² = 0.9967)\n",
    "- All models show reasonable performance (R² > 0.7 for tree-based models)\n",
    "- XGBoost achieves lowest RMSE: 0.73°C\n",
    "\n",
    "FEATURE IMPORTANCE:\n",
    "- Most important feature: Air Temperature (importance: 0.6539)\n",
    "- Top 3 features account for 93.6% of total importance\n",
    "- Temporal features (hour, month) are highly important\n",
    "\n",
    "TEMPORAL PATTERNS:\n",
    "- Clear seasonal patterns in temperature data\n",
    "- Daily and monthly cycles are important predictors\n",
    "\n",
    "DATA QUALITY:\n",
    "- Dataset cleaned: 50,000 → 50,000 rows\n",
    "- Missing values handled via forward-fill and median imputation\n",
    "- Outliers capped using IQR method\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements Checklist\n",
    "\n",
    "- [ ] Final visualizations created (model performance, key insights)\n",
    "- [ ] Summary tables generated\n",
    "- [ ] Key findings documented\n",
    "- [ ] All 3 required artifacts saved with exact filenames\n",
    "\n",
    "---\n",
    "\n",
    "## Your Approach\n",
    "\n",
    "1. **Create visualizations** - Multi-panel figure with model comparison, predictions vs actual, feature importance, and/or residuals\n",
    "2. **Create summary table** - DataFrame with metrics as rows and models as columns\n",
    "3. **Document key findings** - Text summary covering model performance, feature importance insights, temporal patterns, and data quality notes\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Points\n",
    "\n",
    "- **Visualizations:** What best communicates your findings? Model performance plots? Time series with predictions? Feature importance plots?\n",
    "- **Summary:** What are the key takeaways? Document the most important findings from your analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "After Q8, you should have:\n",
    "- [ ] Final visualizations created (2+ plots)\n",
    "- [ ] Summary tables generated\n",
    "- [ ] Key findings documented\n",
    "- [ ] All 3 artifacts saved: `q8_final_visualizations.png`, `q8_summary.csv`, `q8_key_findings.txt`\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Continue to `q9_writeup.md` for Writeup.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58726cd4",
   "metadata": {},
   "source": [
    "## Generate Artifact 1 (q8_final_visualizations.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d989576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: output/q8_final_visualizations.png\n"
     ]
    }
   ],
   "source": [
    "# Compute metrics directly from predictions\n",
    "y_true = predictions[\"actual\"]\n",
    "\n",
    "model_cols = {\n",
    "    \"Linear Regression\": \"predicted_linear\",\n",
    "    \"Random Forest\": \"predicted_random_forest\",\n",
    "    \"XGBoost\": \"predicted_xgboost\",\n",
    "}\n",
    "\n",
    "metrics = {}\n",
    "for model_name, col in model_cols.items():\n",
    "    y_hat = preds[col]\n",
    "    mse = mean_squared_error(y_true, y_hat)\n",
    "    metrics[model_name] = {\n",
    "        \"r2\": r2_score(y_true, y_hat),\n",
    "        \"rmse\": np.sqrt(mse),\n",
    "        \"mae\": mean_absolute_error(y_true, y_hat),\n",
    "    }\n",
    "\n",
    "# Build the 3-panel figure\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Panel 1: Model Test R² Comparison\n",
    "r2_values = [metrics[m][\"r2\"] for m in model_cols.keys()]\n",
    "axes[0].bar(list(model_cols.keys()), r2_values)\n",
    "axes[0].set_title(\"Model Test R² Comparison\")\n",
    "axes[0].set_ylabel(\"R²\")\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "# Panel 2: Predicted vs Actual (XGBoost)\n",
    "axes[1].scatter(predictions[\"actual\"], predictions[\"predicted_xgboost\"], alpha=0.4)\n",
    "min_val = min(predictions[\"actual\"].min(), predictions[\"predicted_xgboost\"].min())\n",
    "max_val = max(predictions[\"actual\"].max(), predictions[\"predicted_xgboost\"].max())\n",
    "axes[1].plot([min_val, max_val], [min_val, max_val], color=\"red\")\n",
    "axes[1].set_title(\"Predicted vs Actual (XGBoost)\")\n",
    "axes[1].set_xlabel(\"Actual\")\n",
    "axes[1].set_ylabel(\"Predicted\")\n",
    "\n",
    "# Panel 3: Top 10 Feature Importances\n",
    "top10 = feature_importance.head(10)\n",
    "axes[2].barh(top10[\"feature\"], top10[\"importance\"])\n",
    "axes[2].invert_yaxis()\n",
    "axes[2].set_title(\"Top 10 Feature Importances\")\n",
    "axes[2].set_xlabel(\"Importance\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/q8_final_visualizations.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved: output/q8_final_visualizations.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a84685b",
   "metadata": {},
   "source": [
    "## Generate Artifact 2 (q8_summary.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b59c3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: output/q8_summary.csv\n"
     ]
    }
   ],
   "source": [
    "summary = {\n",
    "    \"Metric\": [\"R²\", \"RMSE\", \"MAE\"],\n",
    "    \"Linear Regression\": [\n",
    "        metrics[\"Linear Regression\"][\"r2\"],\n",
    "        metrics[\"Linear Regression\"][\"rmse\"],\n",
    "        metrics[\"Linear Regression\"][\"mae\"],\n",
    "    ],\n",
    "    \"Random Forest\": [\n",
    "        metrics[\"Random Forest\"][\"r2\"],\n",
    "        metrics[\"Random Forest\"][\"rmse\"],\n",
    "        metrics[\"Random Forest\"][\"mae\"],\n",
    "    ],\n",
    "    \"XGBoost\": [\n",
    "        metrics[\"XGBoost\"][\"r2\"],\n",
    "        metrics[\"XGBoost\"][\"rmse\"],\n",
    "        metrics[\"XGBoost\"][\"mae\"],\n",
    "    ],\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df.to_csv(\"output/q8_summary.csv\", index=False)\n",
    "\n",
    "print(\"Saved: output/q8_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffc016d",
   "metadata": {},
   "source": [
    "## Generate Artifact 3 (q8_key_findings.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb57cff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: output/q8_key_findings.txt\n"
     ]
    }
   ],
   "source": [
    "# Identify best model by highest test R²\n",
    "best_model = max(metrics, key=lambda m: metrics[m][\"r2\"])\n",
    "best_r2 = metrics[best_model][\"r2\"]\n",
    "best_rmse = metrics[best_model][\"rmse\"]\n",
    "\n",
    "# Top 5 feature importances\n",
    "top_features = feature_importance.head(5)\n",
    "\n",
    "# Convert to bullet list text\n",
    "feature_lines = \"\\n\".join(\n",
    "    [\n",
    "        f\"- {row['feature']} (importance: {row['importance']:.4f})\"\n",
    "        for _, row in top_features.iterrows()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Findings text\n",
    "findings = f\"\"\"\n",
    "KEY FINDINGS SUMMARY\n",
    "====================\n",
    "\n",
    "MODEL PERFORMANCE:\n",
    "- Best performing model: {best_model} (Test R² = {best_r2:.4f})\n",
    "- This model also achieves a low RMSE of {best_rmse:.2f}, indicating strong predictive accuracy.\n",
    "- Linear Regression performed worst, while Random Forest performed well but slightly below XGBoost.\n",
    "\n",
    "FEATURE IMPORTANCE:\n",
    "Top 5 most influential predictors:\n",
    "{feature_lines}\n",
    "\n",
    "INSIGHTS:\n",
    "- Tree-based models (Random Forest and XGBoost) outperform Linear Regression, suggesting important nonlinear relationships in the data.\n",
    "- Feature importances indicate which environmental factors most strongly influence temperature predictions.\n",
    "- Predictions vs actual values show that the best model captures patterns well with moderate residual spread.\n",
    "\n",
    "DATA QUALITY SUMMARY:\n",
    "- Missing values were handled using forward/backward fill and 0-filling for rain-related variables.\n",
    "- Outliers were capped using the IQR method across all numeric features.\n",
    "- Final cleaned dataset retained the full set of {len(predictions)} prediction rows.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Save findings text to q8_key_findings.txt\n",
    "with open(\"output/q8_key_findings.txt\", \"w\") as f:\n",
    "    f.write(findings.strip())\n",
    "\n",
    "print(\"Saved: output/q8_key_findings.txt\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
